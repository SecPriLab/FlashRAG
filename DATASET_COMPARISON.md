# Dataset.py æ–‡ä»¶å¯¹æ¯”åˆ†ææŠ¥å‘Š

## ğŸ“‹ æ¦‚è¿°

`dataset.py` æ˜¯ FlashRAG æ¡†æ¶ä¸­è´Ÿè´£æ•°æ®ç®¡ç†çš„æ ¸å¿ƒæ¨¡å—ã€‚è™½ç„¶ä»è¡¨é¢ä¸Šçœ‹ï¼Œå®˜æ–¹ FlashRAG å’Œ RAG_MIA çš„ `dataset.py` ç»“æ„ç›¸ä¼¼ï¼Œä½†å¯èƒ½å­˜åœ¨ä¸€äº›é’ˆå¯¹ MIA æ”»å‡»éœ€æ±‚çš„ç»†å¾®å·®å¼‚ã€‚

---

## ğŸ” å¯èƒ½çš„å·®å¼‚ç‚¹

### 1. **Output å­—æ®µçš„æ‰©å±•**

#### å®˜æ–¹ FlashRAG çš„ output å­—æ®µé€šå¸¸åŒ…å«ï¼š
```python
item.output = {
    'pred': '...',              # é¢„æµ‹ç­”æ¡ˆ
    'prompt': '...',            # ä½¿ç”¨çš„æç¤ºè¯
    'retrieval_result': [...],  # æ£€ç´¢ç»“æœ
    'metric_score': {...}       # è¯„ä¼°åˆ†æ•°
}
```

#### RAG_MIA å¯èƒ½éœ€è¦é¢å¤–çš„å­—æ®µï¼š
```python
item.output = {
    'pred': '...',
    'prompt': '...',
    'retrieval_result': [...],

    # MIA ä¸“ç”¨å­—æ®µ
    'yes_prob': 0.85,           # yes token çš„æ¦‚ç‡
    'no_prob': 0.15,            # no token çš„æ¦‚ç‡
    'perplexity': 12.34,        # å›°æƒ‘åº¦
    'is_member': True,          # æˆå‘˜æ ‡è®°ï¼ˆground truthï¼‰
    'is_perturbed': False,      # æ˜¯å¦æ˜¯æ‰°åŠ¨æ ·æœ¬
    'original_id': '1234',      # åŸå§‹æ ·æœ¬IDï¼ˆç”¨äºé…å¯¹ï¼‰
}
```

### 2. **Metadata å­—æ®µçš„å·®å¼‚**

#### å®˜æ–¹ FlashRAG çš„ metadataï¼š
```python
item.metadata = {
    'source': 'nq',
    'difficulty': 'hard',
    'category': 'science'
}
```

#### RAG_MIA éœ€è¦çš„ metadataï¼š
```python
item.metadata = {
    'source': 'nq',
    'difficulty': 'hard',
    'category': 'science',

    # MIA ä¸“ç”¨å…ƒæ•°æ®
    'doc_id': '4983',           # å¯¹åº”çš„æ–‡æ¡£ID
    'is_member': True,          # æ˜¯å¦æ˜¯æˆå‘˜æ•°æ®
    'perturbation_ratio': 0.03, # æ‰°åŠ¨æ¯”ä¾‹
    'original_text': '...',     # åŸå§‹æ–‡æœ¬ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
}
```

### 3. **æ•°æ®åŠ è½½é€»è¾‘å¯èƒ½çš„å·®å¼‚**

#### æ ‡å‡†åŠ è½½ï¼ˆå®˜æ–¹ FlashRAGï¼‰ï¼š
```python
def _load_data(self, dataset_name, dataset_path):
    data = []
    with open(dataset_path, 'r') as f:
        for line in f:
            item_dict = json.loads(line)
            item = Item(item_dict)
            data.append(item)
    return data
```

#### MIA å¯èƒ½éœ€è¦çš„é…å¯¹åŠ è½½ï¼š
```python
def _load_data(self, dataset_name, dataset_path):
    data = []
    with open(dataset_path, 'r') as f:
        for line in f:
            item_dict = json.loads(line)

            # MIA ç‰¹æ®Šå¤„ç†ï¼šæ ‡è®°æˆå‘˜/éæˆå‘˜
            if 'is_member' not in item_dict.get('metadata', {}):
                # ä»æ–‡ä»¶åæˆ–å…¶ä»–æ–¹å¼æ¨æ–­
                if 'member' in dataset_path:
                    item_dict['metadata']['is_member'] = True
                elif 'nonmember' in dataset_path:
                    item_dict['metadata']['is_member'] = False

            item = Item(item_dict)
            data.append(item)

    return data
```

---

## ğŸ¯ ä¸ºä»€ä¹ˆ Dataset.py ä¼šæœ‰å·®å¼‚ï¼Ÿ

### åŸå›  1ï¼š**æ•°æ®æ ‡æ³¨éœ€æ±‚**

MIA æ”»å‡»éœ€è¦æ˜ç¡®çš„æˆå‘˜/éæˆå‘˜æ ‡ç­¾ï¼š

```python
# å®˜æ–¹ FlashRAGï¼šåªå…³å¿ƒ QA ä»»åŠ¡
{
    "id": "1",
    "question": "What is...?",
    "golden_answers": ["Answer"]
}

# RAG_MIAï¼šéœ€è¦é¢å¤–çš„æˆå‘˜æ ‡æ³¨
{
    "id": "1",
    "question": "What is...?",
    "golden_answers": ["Answer"],
    "metadata": {
        "is_member": true,      # â† å…³é”®å·®å¼‚
        "doc_id": "4983"        # â† å¯¹åº”çš„æ–‡æ¡£ID
    }
}
```

### åŸå›  2ï¼š**æ‰°åŠ¨æ ·æœ¬é…å¯¹**

MIA éœ€è¦ç»´æŠ¤åŸå§‹æ ·æœ¬å’Œæ‰°åŠ¨æ ·æœ¬çš„å¯¹åº”å…³ç³»ï¼š

```python
# åŸå§‹æ ·æœ¬
original_item = Item({
    "id": "member_0",
    "question": "original question",
    "metadata": {
        "is_member": True,
        "is_perturbed": False,
        "pair_id": "member_0"  # â† é…å¯¹æ ‡è¯†
    }
})

# æ‰°åŠ¨æ ·æœ¬
perturbed_item = Item({
    "id": "member_0_perturbed",
    "question": "perturbed question",
    "metadata": {
        "is_member": True,
        "is_perturbed": True,
        "pair_id": "member_0",     # â† æŒ‡å‘åŸå§‹æ ·æœ¬
        "original_id": "member_0"  # â† åŸå§‹æ ·æœ¬ID
    }
})
```

### åŸå›  3ï¼š**æ¦‚ç‡æ•°æ®å­˜å‚¨**

MIA éœ€è¦å­˜å‚¨å’Œç®¡ç†æ¦‚ç‡æ•°æ®ï¼š

```python
# Dataset ç±»å¯èƒ½æ–°å¢æ–¹æ³•
class Dataset:
    def save_probabilities(self, save_path: str):
        """ä¿å­˜æ‰€æœ‰æ ·æœ¬çš„æ¦‚ç‡æ•°æ®"""
        probs = []
        for item in self.data:
            if 'yes_prob' in item.output and 'no_prob' in item.output:
                probs.append({
                    'id': item.id,
                    'is_member': item.metadata.get('is_member'),
                    'yes_prob': item.output['yes_prob'],
                    'no_prob': item.output['no_prob'],
                    'is_perturbed': item.metadata.get('is_perturbed', False)
                })

        # ä¿å­˜ä¸º PyTorch tensor
        import torch
        member_probs = [p['yes_prob'] for p in probs if p['is_member'] and not p['is_perturbed']]
        torch.save(torch.tensor(member_probs), f"{save_path}/member_yes_probs.pt")

    def load_paired_dataset(self, original_path: str, perturbed_path: str):
        """åŠ è½½åŸå§‹å’Œæ‰°åŠ¨æ ·æœ¬çš„é…å¯¹æ•°æ®é›†"""
        original_data = self._load_data('original', original_path)
        perturbed_data = self._load_data('perturbed', perturbed_path)

        # æ„å»ºé…å¯¹æ˜ å°„
        self.pairs = {}
        for orig, pert in zip(original_data, perturbed_data):
            self.pairs[orig.id] = {
                'original': orig,
                'perturbed': pert
            }
```

---

## ğŸ“Š å…·ä½“å¯èƒ½å­˜åœ¨çš„ä»£ç å·®å¼‚

### å·®å¼‚ 1ï¼šItem.update_output() æ–¹æ³•

#### å®˜æ–¹ FlashRAGï¼ˆä¸¥æ ¼é™åˆ¶ï¼‰ï¼š
```python
def update_output(self, key: str, value: Any) -> None:
    if key in ["id", "question", "golden_answers", "output", "choices"]:
        raise AttributeError(f"{key} should not be changed")
    else:
        self.output[key] = value
```

#### RAG_MIA å¯èƒ½çš„ä¿®æ”¹ï¼ˆå…è®¸æ›´æ–°æŸäº›å­—æ®µï¼‰ï¼š
```python
def update_output(self, key: str, value: Any) -> None:
    # å¯èƒ½æ”¾å®½é™åˆ¶ï¼Œå…è®¸æ›´æ–°æŸäº›å­—æ®µç”¨äº MIA åˆ†æ
    protected_fields = ["id", "question", "golden_answers", "choices"]
    if key in protected_fields:
        raise AttributeError(f"{key} should not be changed")
    else:
        self.output[key] = value

    # æˆ–è€…æ·»åŠ ç‰¹æ®Šå¤„ç†
    if key in ['yes_prob', 'no_prob', 'perplexity']:
        # è‡ªåŠ¨è½¬æ¢ä¸º float æˆ– tensor
        self.output[key] = float(value)
```

### å·®å¼‚ 2ï¼šDataset.save() æ–¹æ³•

#### å®˜æ–¹ FlashRAGï¼š
```python
def save(self, save_path: str) -> None:
    save_data = [item.to_dict() for item in self.data]
    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(save_data, f, indent=4, ensure_ascii=False)
```

#### RAG_MIA å¯èƒ½çš„æ‰©å±•ï¼š
```python
def save(self, save_path: str, save_tensors: bool = False) -> None:
    # æ ‡å‡†çš„ JSON ä¿å­˜
    save_data = [item.to_dict() for item in self.data]
    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(save_data, f, indent=4, ensure_ascii=False)

    # é¢å¤–ä¿å­˜æ¦‚ç‡å¼ é‡ï¼ˆç”¨äº MIA åˆ†æï¼‰
    if save_tensors:
        import torch
        base_path = os.path.dirname(save_path)

        # ä¿å­˜ yes/no æ¦‚ç‡
        member_yes = [item.output.get('yes_prob', 0) for item in self.data
                     if item.metadata.get('is_member', False)
                     and not item.metadata.get('is_perturbed', False)]

        perturb_member_yes = [item.output.get('yes_prob', 0) for item in self.data
                             if item.metadata.get('is_member', False)
                             and item.metadata.get('is_perturbed', False)]

        torch.save(torch.tensor(member_yes), f"{base_path}/member_yes_probs.pt")
        torch.save(torch.tensor(perturb_member_yes), f"{base_path}/perturb_member_yes_probs.pt")
```

### å·®å¼‚ 3ï¼šæ–°å¢çš„é…å¯¹æ–¹æ³•

RAG_MIA å¯èƒ½æ·»åŠ äº†ä¸“é—¨å¤„ç†é…å¯¹æ•°æ®çš„æ–¹æ³•ï¼š

```python
class Dataset:
    def split_by_member_status(self):
        """æŒ‰æˆå‘˜/éæˆå‘˜çŠ¶æ€åˆ†å‰²æ•°æ®é›†"""
        members = [item for item in self.data if item.metadata.get('is_member', False)]
        nonmembers = [item for item in self.data if not item.metadata.get('is_member', True)]

        return Dataset(data=members), Dataset(data=nonmembers)

    def split_by_perturbation(self):
        """æŒ‰æ˜¯å¦æ‰°åŠ¨åˆ†å‰²æ•°æ®é›†"""
        original = [item for item in self.data if not item.metadata.get('is_perturbed', False)]
        perturbed = [item for item in self.data if item.metadata.get('is_perturbed', False)]

        return Dataset(data=original), Dataset(data=perturbed)

    def get_paired_items(self):
        """è·å–é…å¯¹çš„åŸå§‹å’Œæ‰°åŠ¨æ ·æœ¬"""
        pairs = []

        original_items = {item.id: item for item in self.data
                         if not item.metadata.get('is_perturbed', False)}
        perturbed_items = {item.metadata.get('original_id'): item for item in self.data
                          if item.metadata.get('is_perturbed', False)}

        for orig_id in original_items:
            if orig_id in perturbed_items:
                pairs.append({
                    'original': original_items[orig_id],
                    'perturbed': perturbed_items[orig_id]
                })

        return pairs
```

---

## ğŸ”¬ å®é™…ä½¿ç”¨åœºæ™¯å¯¹æ¯”

### åœºæ™¯ 1ï¼šæ ‡å‡† RAG ä»»åŠ¡ï¼ˆå®˜æ–¹ FlashRAGï¼‰

```python
# åŠ è½½æ•°æ®é›†
dataset = Dataset(
    config=config,
    dataset_path='data/nq/test.jsonl'
)

# è¿è¡Œ pipeline
pipeline = SequentialPipeline(config)
result = pipeline.run(dataset)

# è¯„ä¼°
evaluator.evaluate(dataset)

# ä¿å­˜ç»“æœ
dataset.save('output/results.json')
```

### åœºæ™¯ 2ï¼šMIA æ”»å‡»ä»»åŠ¡ï¼ˆRAG_MIAï¼‰

```python
# 1. åŠ è½½æˆå‘˜å’Œéæˆå‘˜æ•°æ®
member_dataset = Dataset(
    config=config,
    dataset_path='data/member_samples.jsonl'
)

nonmember_dataset = Dataset(
    config=config,
    dataset_path='data/nonmember_samples.jsonl'
)

# 2. è¿è¡Œ RAG pipelineï¼ˆæ”¶é›†æ¦‚ç‡ï¼‰
pipeline = SequentialPipeline(config)
member_result = pipeline.run(member_dataset)      # è‡ªåŠ¨ä¿å­˜ yes/no æ¦‚ç‡
nonmember_result = pipeline.run(nonmember_dataset)

# 3. åŠ è½½æ‰°åŠ¨æ ·æœ¬
perturb_member_dataset = Dataset(
    config=config,
    dataset_path='data/perturb_member_samples.jsonl'
)

perturb_nonmember_dataset = Dataset(
    config=config,
    dataset_path='data/perturb_nonmember_samples.jsonl'
)

# 4. å†æ¬¡è¿è¡Œ pipeline
perturb_member_result = pipeline.run(perturb_member_dataset)
perturb_nonmember_result = pipeline.run(perturb_nonmember_dataset)

# 5. æå–æ¦‚ç‡æ•°æ®ï¼ˆDataset å¯èƒ½æœ‰ä¸“é—¨çš„æ–¹æ³•ï¼‰
member_dataset.save_probabilities('output/member')
perturb_member_dataset.save_probabilities('output/perturb_member')
nonmember_dataset.save_probabilities('output/nonmember')
perturb_nonmember_dataset.save_probabilities('output/perturb_nonmember')

# 6. æ‰§è¡Œ MIA æ”»å‡»ï¼ˆä½¿ç”¨ä¿å­˜çš„æ¦‚ç‡ï¼‰
# è¿™éƒ¨åˆ†åœ¨ MIA.py ä¸­å®Œæˆ
```

---

## ğŸ’¡ ä¸ºä»€ä¹ˆè¿™äº›å·®å¼‚æ˜¯å¿…è¦çš„ï¼Ÿ

### 1. **æ•°æ®ç»„ç»‡éœ€æ±‚**

MIA æ”»å‡»éœ€è¦ä¸¥æ ¼çš„æ•°æ®ç»„ç»‡ï¼š
- âœ… æˆå‘˜/éæˆå‘˜æ˜ç¡®åˆ†ç¦»
- âœ… åŸå§‹/æ‰°åŠ¨æ ·æœ¬é…å¯¹
- âœ… æ¦‚ç‡æ•°æ®ä¸æ ·æœ¬å…³è”

### 2. **å®éªŒé‡ç°æ€§**

MIA ç ”ç©¶éœ€è¦ä¿å­˜å®Œæ•´çš„å®éªŒæ•°æ®ï¼š
- âœ… ä¿å­˜åŸå§‹è¾“å…¥
- âœ… ä¿å­˜æ¨¡å‹è¾“å‡ºï¼ˆæ¦‚ç‡ï¼‰
- âœ… ä¿å­˜å…ƒæ•°æ®ï¼ˆæˆå‘˜æ ‡ç­¾ã€æ‰°åŠ¨ä¿¡æ¯ï¼‰

### 3. **åˆ†æä¾¿åˆ©æ€§**

MIA åˆ†æéœ€è¦é«˜æ•ˆçš„æ•°æ®è®¿é—®ï¼š
- âœ… å¿«é€Ÿåˆ†å‰²æ•°æ®é›†ï¼ˆæŒ‰æˆå‘˜çŠ¶æ€ã€æ‰°åŠ¨çŠ¶æ€ï¼‰
- âœ… å¿«é€Ÿæå–æ¦‚ç‡æ•°æ®
- âœ… è‡ªåŠ¨ä¿å­˜ä¸º PyTorch å¼ é‡æ ¼å¼

---

## ğŸ¯ å¯¹ä½ çš„é¡¹ç›®çš„å¯ç¤º

ä½ å½“å‰çš„å®ç°å·²ç»å¾ˆå®Œå–„ï¼Œä½†å¦‚æœè¦è¿›ä¸€æ­¥æ”¯æŒ MIA æ”»å‡»ï¼Œå¯ä»¥è€ƒè™‘æ‰©å±• Dataset ç±»ï¼š

### å»ºè®® 1ï¼šæ·»åŠ  MIA ä¸“ç”¨çš„æ•°æ®ç®¡ç†æ–¹æ³•

```python
# åœ¨ä½ çš„é¡¹ç›®ä¸­æ·»åŠ ä¸€ä¸ª MIA æ•°æ®é›†ç±»
class MIADataset(Dataset):
    """æ‰©å±• Dataset ç±»ä»¥æ”¯æŒ MIA æ”»å‡»"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._validate_mia_data()

    def _validate_mia_data(self):
        """éªŒè¯æ•°æ®é›†æ˜¯å¦åŒ…å« MIA æ‰€éœ€çš„å­—æ®µ"""
        for item in self.data:
            if 'is_member' not in item.metadata:
                raise ValueError(f"Item {item.id} missing 'is_member' in metadata")

    def save_probabilities_as_tensors(self, save_dir: str):
        """ä¿å­˜æ¦‚ç‡æ•°æ®ä¸º PyTorch å¼ é‡"""
        import torch
        import os

        os.makedirs(save_dir, exist_ok=True)

        # æå–æ•°æ®
        member_probs = []
        nonmember_probs = []

        for item in self.data:
            if 'answer_probs' not in item.output:
                continue

            # å‡è®¾ä½¿ç”¨ç¬¬ä¸€ä¸ªç­”æ¡ˆçš„æ¦‚ç‡ä½œä¸ºç½®ä¿¡åº¦
            prob = list(item.output['answer_probs'].values())[0]

            if item.metadata.get('is_member'):
                member_probs.append(prob)
            else:
                nonmember_probs.append(prob)

        # ä¿å­˜
        if member_probs:
            torch.save(torch.tensor(member_probs),
                      f"{save_dir}/member_probs.pt")
        if nonmember_probs:
            torch.save(torch.tensor(nonmember_probs),
                      f"{save_dir}/nonmember_probs.pt")

    def get_paired_samples(self):
        """è·å–åŸå§‹-æ‰°åŠ¨æ ·æœ¬å¯¹"""
        pairs = {}

        for item in self.data:
            if item.metadata.get('is_perturbed'):
                orig_id = item.metadata.get('original_id')
                if orig_id not in pairs:
                    pairs[orig_id] = {}
                pairs[orig_id]['perturbed'] = item
            else:
                if item.id not in pairs:
                    pairs[item.id] = {}
                pairs[item.id]['original'] = item

        return pairs
```

### å»ºè®® 2ï¼šä¿®æ”¹æ•°æ®å‡†å¤‡è„šæœ¬

```python
# åœ¨ prepare_mia_data.py ä¸­ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
def create_query_dataset(member_docs, nonmember_docs, output_path):
    queries = []

    # æˆå‘˜æ ·æœ¬
    for idx, doc in enumerate(member_docs):
        query = {
            'id': f'member_{idx}',
            'question': doc['title'],
            'golden_answers': [],
            'metadata': {
                'doc_id': doc['_id'],
                'is_member': True,           # â† MIA å¿…éœ€
                'is_perturbed': False,       # â† MIA å¿…éœ€
                'full_text': doc['text']
            }
        }
        queries.append(query)

    # éæˆå‘˜æ ·æœ¬
    for idx, doc in enumerate(nonmember_docs):
        query = {
            'id': f'nonmember_{idx}',
            'question': doc['title'],
            'golden_answers': [],
            'metadata': {
                'doc_id': doc['_id'],
                'is_member': False,          # â† MIA å¿…éœ€
                'is_perturbed': False,       # â† MIA å¿…éœ€
                'full_text': doc['text']
            }
        }
        queries.append(query)

    save_jsonl(queries, output_path)
```

---

## ğŸ“– æ€»ç»“

### Dataset.py å¯èƒ½å­˜åœ¨çš„å·®å¼‚åŸå› ï¼š

1. **æ•°æ®æ ‡æ³¨**ï¼šMIA éœ€è¦æ˜ç¡®çš„æˆå‘˜/éæˆå‘˜æ ‡ç­¾
2. **é…å¯¹ç®¡ç†**ï¼šMIA éœ€è¦ç»´æŠ¤åŸå§‹-æ‰°åŠ¨æ ·æœ¬çš„å¯¹åº”å…³ç³»
3. **æ¦‚ç‡å­˜å‚¨**ï¼šMIA éœ€è¦é«˜æ•ˆåœ°ä¿å­˜å’ŒåŠ è½½æ¦‚ç‡æ•°æ®
4. **åˆ†æä¾¿åˆ©**ï¼šMIA éœ€è¦ä¸“é—¨çš„æ•°æ®åˆ†å‰²å’Œæå–æ–¹æ³•

### æ ¸å¿ƒå·®å¼‚ç‚¹ï¼š

| æ–¹é¢ | å®˜æ–¹ FlashRAG | RAG_MIA å¯èƒ½çš„ä¿®æ”¹ |
|------|--------------|-------------------|
| **Metadata** | åŸºæœ¬ä»»åŠ¡ä¿¡æ¯ | æ·»åŠ  is_member, is_perturbed ç­‰ |
| **Output** | é¢„æµ‹ç»“æœ | æ·»åŠ  yes_prob, no_prob, perplexity ç­‰ |
| **Save** | ä¿å­˜ JSON | é¢å¤–ä¿å­˜ PyTorch å¼ é‡ |
| **åŠ è½½** | æ ‡å‡†åŠ è½½ | å¯èƒ½æ”¯æŒé…å¯¹åŠ è½½ |
| **æ–°æ–¹æ³•** | æ—  | split_by_member_status(), save_probabilities() ç­‰ |

### å¯¹ä½ çš„é¡¹ç›®ï¼š

ä½ çš„å½“å‰å®ç°å·²ç»æ”¯æŒäº† MIA çš„æ ¸å¿ƒåŠŸèƒ½ï¼ˆè¿”å› logitsã€æ–‡æ¡£IDç­‰ï¼‰ï¼Œå¦‚æœéœ€è¦å®Œæ•´çš„ MIA æ”»å‡»æµç¨‹ï¼Œå»ºè®®ï¼š

1. âœ… æ‰©å±• Dataset ç±»æ·»åŠ  MIA ä¸“ç”¨æ–¹æ³•
2. âœ… åœ¨æ•°æ®å‡†å¤‡é˜¶æ®µæ·»åŠ å¿…éœ€çš„ metadata å­—æ®µ
3. âœ… å®ç°æ¦‚ç‡æ•°æ®çš„æ‰¹é‡ä¿å­˜å’ŒåŠ è½½
4. âœ… æ·»åŠ é…å¯¹æ ·æœ¬ç®¡ç†åŠŸèƒ½

---

**æŠ¥å‘Šå®Œæˆæ—¶é—´**: 2025-11-12
